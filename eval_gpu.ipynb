{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import ImageFolder\n",
    "import torch.nn.functional as functional\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the image transformation pipeline\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Define device to be used (GPU or CPU)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Load pre-trained models\n",
    "resnet18 = models.resnet18(pretrained=True).to(device)\n",
    "vgg19 = models.vgg19(pretrained=True).to(device)\n",
    "inception = models.inception_v3(pretrained=True).to(device)\n",
    "\n",
    "# Set all models to eval mode (not training mode)\n",
    "resnet18.eval();\n",
    "vgg19.eval();\n",
    "inception.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "phase = 'train'\n",
    "train_path = 'code_test_data/'+ phase\n",
    "\n",
    "# Load the custom dataset\n",
    "dataset = ImageFolder(train_path, transform=transform)\n",
    "\n",
    "# Get a list of unique class labels\n",
    "classes = list(set(dataset.classes))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use torch.no_grad(): If you're not updating the parameters of your model during evaluation, you can use the torch.no_grad() context manager to avoid keeping track of the gradients. This can reduce memory usage significantly."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creation of dictionary "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a temp dictionary to store feature vectors for each class\n",
    "temp_dict = {}\n",
    "for cls in classes:\n",
    "    temp_dict[cls] = []\n",
    "\n",
    "# Initialize new dictionary with null values\n",
    "features_vgg = {key: None for key in temp_dict}\n",
    "features_resnet = {key: None for key in temp_dict}\n",
    "features_inception = {key: None for key in temp_dict}\n",
    "\n",
    "# Iterate over the dataset and extract feature vectors for each class\n",
    "loader = DataLoader(dataset, batch_size=1, shuffle=True)\n",
    "for images, labels in loader:\n",
    "\n",
    "    # Send the labels to the GPU\n",
    "    labels = labels.to(device)\n",
    "    # Send the images to the GPU\n",
    "    images = images.to(device)\n",
    "    \n",
    "    cls = dataset.classes[labels[0]]\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        # for resnet18\n",
    "        features_tensor = resnet18(images)\n",
    "        features_vector_resnet = functional.normalize(features_tensor, p=2, dim=-1)\n",
    "\n",
    "        # for vgg19\n",
    "        features_tensor = vgg19(images)\n",
    "        features_vector_vgg = functional.normalize(features_tensor, p=2, dim=-1)\n",
    "\n",
    "        # for inception\n",
    "        features_tensor = inception(images)\n",
    "        features_vector_inception = functional.normalize(features_tensor, p=2, dim=-1)\n",
    "\n",
    "        # # Print the number of rows\n",
    "        # print(num_rows)\n",
    "        if features_vgg[cls] is None:\n",
    "            # print('features[cls] exists but has an empty/null value')\n",
    "            features_vgg[cls] = features_vector_vgg\n",
    "            features_resnet[cls] = features_vector_resnet\n",
    "            features_inception[cls] = features_vector_inception\n",
    "        else:\n",
    "            # print('features[cls] exists and contains a non-empty/non-null value')\n",
    "            features_vgg[cls] = torch.cat((features_vgg[cls], features_vector_vgg), dim=0)  \n",
    "            features_resnet[cls] = torch.cat((features_resnet[cls], features_vector_resnet), dim=0) \n",
    "            features_inception[cls] = torch.cat((features_inception[cls], features_vector_inception), dim=0)   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# features_vgg[cls]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the average feature vector for each class\n",
    "for cls in classes:\n",
    "    features_vgg[cls] = torch.mean(features_vgg[cls], dim=0).unsqueeze(0)\n",
    "    features_resnet[cls] = torch.mean(features_resnet[cls], dim=0).unsqueeze(0)\n",
    "    features_inception[cls] = torch.mean(features_inception[cls], dim=0).unsqueeze(0)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phase = 'test'\n",
    "test_path = 'code_test_data/'+ phase\n",
    "\n",
    "# Load the custom dataset\n",
    "test_dataset = ImageFolder(test_path, transform=transform)\n",
    "\n",
    "# Get a list of unique class labels\n",
    "classes = list(set(test_dataset.classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary to store one image per class\n",
    "img_dict = {}\n",
    "\n",
    "# Iterate over the dataset and extract feature vectors for each class\n",
    "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for img, label in test_loader:\n",
    "\n",
    "  # Send the labels to the GPU\n",
    "  label = label.to(device)\n",
    "  # Send the images to the GPU\n",
    "  img = img.to(device)  \n",
    "  \n",
    "  if label not in img_dict:\n",
    "    img_dict[label] = img\n",
    "  # Break the loop if all classes are found\n",
    "  if len(img_dict) == len(classes): # num_classes is the number of classes in your dataset\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose one random image per class and compare its feature vector with others\n",
    "correct = 0\n",
    "total = len(classes)\n",
    "\n",
    "temp_dict = {}\n",
    "for cls in classes:\n",
    "    temp_dict[cls] = []\n",
    "\n",
    "# Initialize new dictionary with null values\n",
    "resnet_similarities = {key: None for key in temp_dict}\n",
    "vgg_similarities = {key: None for key in temp_dict}\n",
    "inception_similarities = {key: None for key in temp_dict}\n",
    "\n",
    "for cls in classes:\n",
    "    temp_dict[cls] = []\n",
    "\n",
    "for label,image in img_dict.items():\n",
    "\n",
    "    # Send the labels to the GPU\n",
    "    label = label.to(device)\n",
    "    # Send the images to the GPU\n",
    "    image = image.to(device)\n",
    "    \n",
    "    present_probe_cls = label\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        # for resnet18\n",
    "        features_tensor = resnet18(image)\n",
    "        features_vector_resnet = functional.normalize(features_tensor, p=2, dim=-1)\n",
    "        # for vgg19\n",
    "        features_tensor = vgg19(image)\n",
    "        features_vector_vgg = functional.normalize(features_tensor, p=2, dim=-1)\n",
    "        # for inception\n",
    "        features_tensor = inception(image)\n",
    "        features_vector_inception = functional.normalize(features_tensor, p=2, dim=-1)   \n",
    "        \n",
    "        # Compute the cosine similarity between the feature vector and the average feature vector for each class\n",
    "        # Create a CosineSimilarity object with dim=0\n",
    "        cos_sim = torch.nn.CosineSimilarity(dim=0)\n",
    "        for cls in classes:\n",
    "            temp = cos_sim(features_vector_resnet.unsqueeze(0), features_resnet[cls].unsqueeze(0))\n",
    "            resnet_similarities[cls] = torch.mean(temp).unsqueeze(0)\n",
    "\n",
    "            temp = cos_sim(features_vector_vgg.unsqueeze(0), features_vgg[cls].unsqueeze(0))\n",
    "            vgg_similarities[cls] = torch.mean(temp).unsqueeze(0)\n",
    "\n",
    "            temp = cos_sim(features_vector_inception.unsqueeze(0), features_inception[cls].unsqueeze(0))\n",
    "            inception_similarities[cls] = torch.mean(temp).unsqueeze(0)\n",
    "\n",
    "        # Compute the avg similarity for each class\n",
    "        avg_similarity = {}\n",
    "        for cls in classes:\n",
    "            avg_similarity[cls] = (resnet_similarities[cls] + vgg_similarities[cls] + inception_similarities[cls])/3\n",
    "        # Make a prediction based on the class with the highest cosine similarity\n",
    "        max_key = max(avg_similarity, key=avg_similarity.get)\n",
    "        # here max_key is the predicted class\n",
    "        if present_probe_cls == max_key:\n",
    "            correct += 1\n",
    "        # total += 1\n",
    "    # print(\"value of correct is\", correct)\n",
    "# Print the accuracy\n",
    "print('Accuracy: {:.2f}%'.format(correct / total * 100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9cbce6e882a989494bd6e695b5d73f3ae120927e1657582a8b4fc7aae15280bc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
